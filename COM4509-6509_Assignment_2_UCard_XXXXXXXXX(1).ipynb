{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Brief \n",
    "\n",
    "## Deadline: Tuesday, December 3, 2019 at 14:00 hrs\n",
    "\n",
    "## Number of marks available: 20\n",
    "\n",
    "## Scope: Sessions 6 to 9\n",
    "\n",
    "## 1. Instructions\n",
    "### How and what to submit\n",
    "\n",
    "A. Submit a Jupyter Notebook named COM4509-6509_Assignment_2_UCard_XXXXXXXXX.ipynb where XXXXXXXXX refers to your UCard number.\n",
    "\n",
    "B. Upload the notebook file to MOLE before the deadline above.\n",
    "\n",
    "C. **NO DATA UPLOAD**: Please do not upload the data files used. We have a copy already. \n",
    "\n",
    "\n",
    "### Assessment Criteria \n",
    "\n",
    "* Being able to manipulate a dataset by generating sythetic data and extracting a particular subset. \n",
    "\n",
    "* Being able to build and train different machine learning models with tunable hyperparameters to optimise given evaluation metric.\n",
    "\n",
    "* Being able to compare different machine learning models and explain interesting results observed. \n",
    "\n",
    "* Being able to follow examples in the lab and write code without the help of starter code.\n",
    "\n",
    "\n",
    "### Late submissions\n",
    "\n",
    "We follow Department's guidelines about late submissions, i.e., a deduction of 5% of the mark each working day the work is late after the deadline. NO late submission will be marked one week after the deadline because we will release a solution by then. Please read [this link](https://sites.google.com/sheffield.ac.uk/compgtstudenthandbook/menu/assessment/late-submission?pli=1&authuser=1). \n",
    "\n",
    "### Use of unfair means \n",
    "\n",
    "**\"Any form of unfair means is treated as a serious academic offence and action may be taken under the Discipline Regulations.\"** (from the MSc Handbook). Please carefully read [this link](https://sites.google.com/sheffield.ac.uk/compgtstudenthandbook/menu/referencing-unfair-means?pli=1&authuser=1) on what constitutes Unfair Means if not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image classification and denoising\n",
    "\n",
    "### The CIFAR-10 dataset\n",
    "In this assignment, we will work on the [**CIFAR-10 dataset**](https://www.cs.toronto.edu/~kriz/cifar.html) collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton from the University of Toronto.  This dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. Each image is a 3-channel colour images of 32x32 pixels in size. There are 50000 training images and 10000 test images. \n",
    "\n",
    "\t\t\t\n",
    "### Question 1: Data loading and manipulation (4 marks)\n",
    "\n",
    "1a. **Download** both the training and test data of the CIFAR-10 dataset, e.g., by following the [pytorch CIFAR10 tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). You can also download via other ways if you prefer.\n",
    "\n",
    "1b. **Add random noise** to all training and test data to generate noisy dataset, e.g., by `torch.randn()`, with a scaling  factor `scale`, e.g., original image `+ scale * torch.randn()`, and **normalise/standardise** the pixel values to the **original range**, e.g.,  using `np.clip()`. You may choose any `scale` value between 0.2 and 0.5. \n",
    "\n",
    "**Note: Before generating the random noise, you MUST set the random seed to your UCard number XXXXXXXXX for reproducibility, e.g., using `torch.manual_seed()`. This seed needs to be used for all remaining code if there is randomness, for reproducibility.**\n",
    "\n",
    "1c. **Extract a subset** with only two classes: **Cat** and **Dog** and name it starting with **CatDog**.        \n",
    "\n",
    "1d. Show 10 pairs of original and noisy images of cats and 10 pairs of original and noisy images of dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Write the code for your answer here. You can use multiple cells to improve readability.\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# import numpy as np\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1b. Add random noise\n",
    "1c. Extract a subset\n",
    "\"\"\"\n",
    "\n",
    "torch.manual_seed(1647052)\n",
    "scale = 0.5\n",
    "#image = image + (torch.rand(1)*scale)\n",
    "\n",
    "\"\"\"\n",
    "Images without noise \n",
    "\"\"\"\n",
    "train_images = []\n",
    "cat_images = []\n",
    "dog_images = []\n",
    "\n",
    "\"\"\"\n",
    "Images with noise \n",
    "\"\"\"\n",
    "train_images_noise = []\n",
    "cat_images_noise = []\n",
    "dog_images_noise = []\n",
    "\n",
    "\"\"\"\n",
    "Labels\n",
    "\"\"\"\n",
    "train_labels = []\n",
    "cat_labels = []\n",
    "dog_labels = []\n",
    "\n",
    "for data in trainloader:\n",
    "    image, label = data \n",
    "    train_images.append(image)\n",
    "    train_images_noise.append(image + (torch.rand(1)*scale))\n",
    "    train_labels.append(label)\n",
    "    if label == 3:\n",
    "        cat_images.append(image)\n",
    "        cat_images_noise.append(image + (torch.rand(1)*scale))\n",
    "        cat_labels.append(label)\n",
    "    elif label == 5:\n",
    "        dog_images.append(image)\n",
    "        dog_images_noise.append(image + (torch.rand(1)*scale))\n",
    "        dog_labels.append(label)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1d. Show 10 pairs of original and noisy images of cats and 10 pairs of original and noisy images of dogs\n",
    "\n",
    "TO-DO original AND noisy images\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "CatDog = cat_images + dog_images\n",
    "CatDogLabels = cat_labels + dog_labels\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "for i in range(10):\n",
    "    imshow(torchvision.utils.make_grid(CatDog[i]))\n",
    "\n",
    "dogs = CatDog[-10:] \n",
    "\n",
    "for i in dogs:\n",
    "    imshow(torchvision.utils.make_grid(i))\n",
    "# # get some random training images\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# # print labels\n",
    "# print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Dimensionality reduction, binary classification, and evaluation (6 marks)\n",
    "\n",
    "This question uses the **CatDog** subset **with no noise added**.\n",
    "\n",
    "#### Training\n",
    "\n",
    "2a. Apply PCA on the training set to reduce the dimensionality. You need to study **at least seven** different values ($k_1, k_2, ..., k_7$) for the reduced dimensionality. **Explain** your choice.\n",
    "\n",
    "2b. Train **eight** Naive Bayes Classifiers (NBC): one on the original features (raw pixels), and seven on PCA features with seven different dimensions in 2a, i.e., NBC on $k_1$ PCA features; NBC on $k_2$ PCA features; ..., NBC on $k_7$ PCA features. You will need to decide on what Naive Bayes classifier (Gaussian? Multinomial? etc.) to use and **explain** your choice.\n",
    "\n",
    "#### Testing and evaluation\n",
    "2c. Evalaute the eight Naive Bayes classifiers on the test set in terms of **classification accuracy** and **visualise** their performance using a bar graph.\n",
    "\n",
    "2d. Plot the [ROC Curves](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) in true positive rates vs false positive rates for the eight Naive Bayes classifiers in **one figure** using eight different line/marker styles clearly labelled. \n",
    "\n",
    "2e. Compute the [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve) values for the eight Naive Bayes classifiers and visualise using a bar graph.\n",
    "\n",
    "2f. Describe **at least three** interesting observations from the evaluation results above. Each observation should have **3-5 sentences**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your answer here. You can use multiple cells to improve readability.\n",
    "\"\"\"\n",
    "2a. Apply PCA on the training set \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "#convert CatDog to numpy array\n",
    "CatDog_stack = torch.stack(CatDog)\n",
    "CatDog_stack = np.squeeze(CatDog_stack.numpy())\n",
    "CatDog_pca = CatDog_stack.reshape(CatDog_stack.shape[0],-1)\n",
    "\n",
    "pca = PCA(svd_solver='randomized',\n",
    "          whiten=True).fit(CatDog_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[561, 376, 283, 225, 184, 154, 132]\n"
     ]
    }
   ],
   "source": [
    "eigenvectors_total_sum = sum(pca.explained_variance_)\n",
    "percentage_variance = [0.99,0.98,0.97,0.96,0.95,0.94,0.93]\n",
    "values_of_k = []\n",
    "for i in percentage_variance:\n",
    "    k = 0\n",
    "    current_eigenvectors_sum = 0\n",
    "    while(current_eigenvectors_sum / eigenvectors_total_sum <= i):\n",
    "        current_eigenvectors_sum += pca.explained_variance_[k]\n",
    "        k += 1\n",
    "    values_of_k.append(k)\n",
    "    \n",
    "print(values_of_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use values of k that explained the following percentage of variance: 99%, 98%, 97%, 96%, 95%, 94%, 93%. This is because 93-99% is a high percentage of explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31764707 0.3372549  0.36078432 ... 0.09411765 0.09411765 0.08627451]\n",
      " [0.4        0.34901962 0.3529412  ... 1.         1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         0.99607843]\n",
      " ...\n",
      " [0.6745098  0.67058825 0.6666667  ... 0.67058825 0.6627451  0.6392157 ]\n",
      " [0.         0.00784314 0.01960784 ... 0.2        0.18039216 0.18431373]\n",
      " [0.8745098  0.9098039  0.92941177 ... 0.07843138 0.07450981 0.0627451 ]]\n",
      "(10000, 3072) (10000,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "2b. Train eight Naive Bayes Classifiers (NBC)\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "CatDogLabels_nb = np.asarray(CatDogLabels)\n",
    "mnb = MultinomialNB()\n",
    "mnb1 = MultinomialNB()\n",
    "mnb2 = MultinomialNB()\n",
    "mnb3 = MultinomialNB()\n",
    "mnb4 = MultinomialNB()\n",
    "mnb5 = MultinomialNB()\n",
    "mnb6 = MultinomialNB()\n",
    "mnb7 = MultinomialNB()\n",
    "\n",
    "model = []\n",
    "#train with all features\n",
    "model_k0 = mnb.fit(CatDog_pca, CatDogLabels_nb)\n",
    "#train with k number of features\n",
    "model_k1 = mnb1.fit(CatDog_pca[:,:values_of_k[0]], CatDogLabels_nb)\n",
    "model_k2 = mnb2.fit(CatDog_pca[:,:values_of_k[1]], CatDogLabels_nb)\n",
    "model_k3 = mnb3.fit(CatDog_pca[:,:values_of_k[2]], CatDogLabels_nb)\n",
    "model_k4 = mnb4.fit(CatDog_pca[:,:values_of_k[3]], CatDogLabels_nb)\n",
    "model_k5 = mnb5.fit(CatDog_pca[:,:values_of_k[4]], CatDogLabels_nb)\n",
    "model_k6 = mnb6.fit(CatDog_pca[:,:values_of_k[5]], CatDogLabels_nb)\n",
    "model_k7 = mnb7.fit(CatDog_pca[:,:values_of_k[6]], CatDogLabels_nb)\n",
    "\n",
    "model.append(model_k1)\n",
    "model.append(model_k2)\n",
    "model.append(model_k3)\n",
    "model.append(model_k4)\n",
    "model.append(model_k5)\n",
    "model.append(model_k6)\n",
    "model.append(model_k7)\n",
    "print(CatDog_pca)\n",
    "\n",
    "print(CatDog_pca.shape, CatDogLabels_nb.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes is used for continuous data and Multinomial Naive Bayes is used for discrete data. The RGB values are discrete since there are upper and lower limits to each RGB value. Therefore Multinomial Naive Bayes has been used for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2c. Evalaute the eight Naive Bayes classifiers on the test set \n",
    "\"\"\"\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for data in testloader:\n",
    "    image, label = data \n",
    "    test_images.append(image)\n",
    "    test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "0.1134\n",
      "[0.1134, 0.1141, 0.1157, 0.1152, 0.1145, 0.1143, 0.1126, 0.1086]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_images_stack = torch.stack(test_images)\n",
    "test_images_stack = np.squeeze(test_images_stack.numpy())\n",
    "test_images_pca = test_images_stack.reshape(test_images_stack.shape[0],-1)\n",
    "\n",
    "test_labels_nb = np.asarray(test_labels)\n",
    "\n",
    "print(test_images_pca.shape)\n",
    "\n",
    "initial_model_labels = model_k0.predict(test_images_pca)\n",
    "initial_accuracy = accuracy_score(test_labels_nb, initial_model_labels)\n",
    "\n",
    "print(initial_accuracy)\n",
    "accuracy = []\n",
    "#add the k value for all features to the start of values_of_k array \n",
    "#This is because this value will be used for model[0] (the model with all features)\n",
    "for i in range(len(model)):\n",
    "    model_labels = model[i].predict(test_images_pca[:,:values_of_k[i]])\n",
    "    acc = accuracy_score(test_labels_nb, model_labels)\n",
    "    accuracy.append(acc)\n",
    "\n",
    "#insert the initial_accuracy into the accuracy list\n",
    "accuracy.insert(0,initial_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = ['model_0','model_k1', 'model_k2', 'model_k3', 'model_k4', 'model_k5', 'model_k6', 'model_k7']\n",
    "x_pos = [i for i, _ in enumerate(x_axis)]\n",
    "plt.bar(x_pos, accuracy)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy of the 8 models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Noisy data and multiclass classification (6 marks)\n",
    "\n",
    "#### Noisy **CatDog** subset.\n",
    "\n",
    "3a. Repeat 2a, 2b, and 2c on the noisy version of CatDog subset. Show the bar graph and compare it with that in 2c above. \n",
    "\n",
    "#### Multiclass classification using the original CIFAR-10 dataset (all 10 classes)\n",
    "\n",
    "3b. Apply PCA on the training set to reduce the dimensionality. You need to study at least **three** different values for the reduced dimensionality. Explain your choice.\n",
    "\n",
    "3c. Train nine classifers: **four Naive Bayes** classifiers(one on the original features, and three on PCA features with three different dimensions in 3b); **four Logistic Regression** classifiers (one on the original features, and three on PCA features with three different dimensions in 3b); and one **Convoluational Neural Network** as defined in the [pytorch CIFAR10 tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "3d. Evalaute the nine classifiers on the test set. Summarise the **classification accuracy**, **total training time**, and **total test time** using three bar graphs.\n",
    "\n",
    "3e. Show the confusion matrix for these nine classifiers (see Lab 8 - 1.4).\n",
    "\n",
    "3f. Describe **at least three** interesting observations from the evaluation results above. Each observation should have **3-5 sentences**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your answer here. You can use multiple cells to improve readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Denoising Autoencoder (4 marks)\n",
    "\n",
    "This question uses both the original and noisy CIFAR-10 datasets (all 10 classes).\n",
    "\n",
    "Read about denoising autoencoder at [Wikepedia](https://en.wikipedia.org/wiki/Autoencoder#Denoising_autoencoder_(DAE)) and this [short introduction](https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2) or any other sources you like.\n",
    "\n",
    "4a. Modify the autoencoder architecture in Lab 7 so that it takes colour images as input (i.e., 3 input channels). \n",
    "\n",
    "4b. **Training**: feed the **noisy training images** as input to the autoencoder in 4a; use a loss function that computes the reconstruction error between the **output of the autoencoder** and the respective **original images**.\n",
    "\n",
    "4c. **Testing**: evaluate the autoencoder trained in 4b on the test datasets (feed noisy images in and compute reconstruction errors on original clean images. Find the **worstly denoised** 30 images (those with the largest reconstruction errors) in the test set and show them in pairs with the original images (60 images to show in total).\n",
    "\n",
    "4d. Choose at least two hyperparameters to vary. Study **at least three different choices** for each hyperparameter. When varying one hyperparameter, all the other hyperparameters can be fixed. Visualise the performance sensitivity with respect to these hyperparameters.\n",
    "\n",
    "4e. Describe **at least two** interesting observations from the evaluation results above. Each observation should have **3-5 sentences**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code for your answer here. You can use multiple cells to improve readability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
